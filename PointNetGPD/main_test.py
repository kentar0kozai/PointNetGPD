# -*- coding: utf-8 -*-
from __future__ import print_function
import argparse
import time

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from model.pointnet import PointNetSkipAtCls

parser = argparse.ArgumentParser(description="pointnetGPD")
parser.add_argument("--cuda", action="store_true", default=True)
parser.add_argument("--gpu", type=int, default=0)
parser.add_argument("--load-model", type=str, default="./assets/learned_models/PointNet_SkipAt/PointNet_SkipAt_200.model")
parser.add_argument("--model-points", type=int, default=750)
parser.add_argument("--n-repeat", type=int, default=10)
args = parser.parse_args()

# GPUè¨­å®š
args.cuda = args.cuda if torch.cuda.is_available() else False
device = torch.device(f"cuda:{args.gpu}" if args.cuda else "cpu")
if args.cuda:
    torch.cuda.manual_seed(1)
np.random.seed(int(time.time()))

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
checkpoint = torch.load(args.load_model, map_location="cpu", weights_only=False)
model = checkpoint.module if hasattr(checkpoint, "module") else checkpoint
model.eval()
model.to(device)
print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {args.load_model}")

# â”€â”€ ã“ã“ã‹ã‚‰ç”Ÿã® test.npy å‰å‡¦ç†ä»˜ãæ¨è«– â”€â”€
# 1. ç‚¹ç¾¤ã‚’ãƒ­ãƒ¼ãƒ‰
pc_raw = np.load("test.npy")  # shape=(M,3)
M = pc_raw.shape[0]
print(f"Loaded raw point cloud with {M} points")


# 2. Datasetç›¸å½“ã®å‰å‡¦ç†é–¢æ•°ã‚’å®šç¾©
def preprocess_point_cloud(pc, num_points):
    # â‘  ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° or ãƒªãƒ—ãƒ¬ã‚¤ã‚¹ã‚ã‚ŠæŠ½å‡º
    if pc.shape[0] >= num_points:
        idxs = np.random.choice(pc.shape[0], num_points, replace=False)
    else:
        idxs = np.random.choice(pc.shape[0], num_points, replace=True)
    pc_sampled = pc[idxs, :]  # (num_points, 3)

    # â‘¡ é‡å¿ƒã‚’å¼•ã„ã¦ã‚»ãƒ³ã‚¿ãƒªãƒ³ã‚°
    centroid = np.mean(pc_sampled, axis=0)
    pc_centered = pc_sampled - centroid  # (num_points, 3)

    # â‘¢ æœ€å¤§è·é›¢ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆåŠå¾„ã‚’1ã«æ­£è¦åŒ–ï¼‰
    furthest_dist = np.max(np.linalg.norm(pc_centered, axis=1))
    if furthest_dist > 0:
        pc_normalized = pc_centered / furthest_dist
    else:
        pc_normalized = pc_centered

    # â‘£ è»¢ç½®ã—ã¦ (3, num_points) ã«
    return pc_normalized.T.astype(np.float32)


# 3. è¤‡æ•°å›ç¹°ã‚Šè¿”ã—ã¦æŠ•ã’ã‚‹å ´åˆã®å‡¦ç†ãƒ«ãƒ¼ãƒ—
all_logits = []
all_probs = []
all_preds = []

for _ in range(args.n_repeat):
    # å‰å‡¦ç†ã—ã¦ãƒ†ãƒ³ã‚½ãƒ«åŒ–
    pc_proc = preprocess_point_cloud(pc_raw, args.model_points)  # (3,750)
    pc_tensor = torch.from_numpy(pc_proc).unsqueeze(0).to(device)  # (1,3,750)

    # æ¨è«–
    with torch.no_grad():
        logits, _ = model(pc_tensor)  # (1,2)
        probs = F.softmax(logits, dim=-1)  # (1,2)

    # CPUã¸æˆ»ã—ã¦ numpy ã«
    logits_np = logits.cpu().numpy()[0]  # shape=(2,)
    probs_np = probs.cpu().numpy()[0]  # shape=(2,)
    pred = int(probs_np.argmax())  # äºˆæ¸¬ãƒ©ãƒ™ãƒ«

    all_logits.append(logits_np)
    all_probs.append(probs_np)
    all_preds.append(pred)

# 4. çµæœã‚’ã¾ã¨ã‚ã¦è¡¨ç¤º
all_logits = np.stack(all_logits, axis=0)  # (n_repeat,2)
all_probs = np.stack(all_probs, axis=0)  # (n_repeat,2)
all_preds = np.array(all_preds)  # (n_repeat,)

# å¹³å‡logits, å¹³å‡ç¢ºç‡, æœ€é »å€¤ï¼ˆvotingï¼‰
mean_logits = all_logits.mean(axis=0)
mean_probs = all_probs.mean(axis=0)
from scipy.stats import mode

vote_label = int(mode(all_preds).mode.item())

print("ğŸ” raw logitsï¼ˆrepeatå¹³å‡ï¼‰:", mean_logits)
print("âœ¨ softmax probabilitiesï¼ˆrepeatå¹³å‡ï¼‰:", mean_probs)
print("ğŸ·ï¸ votingäºˆæ¸¬ãƒ©ãƒ™ãƒ«:", vote_label)
